---
header-includes: |
    \usepackage{caption}
    \usepackage{subcaption}
    \usepackage{graphicx}
...

# Supervised Learning

Name: Nick Merlene 

GT ID: nmerlene3

## Abstract

The purpose of this assignment is to explore two interesting classification problems using five different supervised learning algorithms.
The chosen datasets are housing prices in Melbourne, Australia and Red Wine Quality, both of which were downloaded from Kaggle.
The learning algorithms analyzed are Decision Trees, Boosting, k-Nearest Neighbors, Support Vector Machines, and Neural Networks.
All analysis was done in Python using `numpy` and `scikit-learn`.

## Datasets

| Dataset | Label   | % Train/Test | Training Samples | Testing Samples | % Null Values | # Features | # Labels |
| ------- | ------- | ------------ | ---------------- | --------------- | ------------- | ---------- | -------- |
| Housing | Price   | 75%/25%      | 4647             | 1549            | 54.4%         | 16/20      | 3        |
| Wine    | Quality | 75%/25%      | 1199             | 400             | 0.0%          | 11/11      | 2        |

Table: Datasets

The first dataset selected was on Melbourne housing prices (hereafter referred to as *Housing*) from January of 2016 to December of 2017,
scraped from *Domain.com.au*.
In addition to the price each home sold for, there are 20 other columns detailing other information about the home,
such as the type of home, how many rooms it has, the date it was sold and more.
As shown in `Table 1` above, *Price* was selected as the label and 16/20 of the remaining columns were selected as features.
*One-Hot Encoding* was applied for any categorical features that were not ordinal, e.g. the name of the region the home was sold in,
while *Label Encoding* was applied to other non-numerical features, e.g. the date the home was sold.
Any rows with null data (54.4% of the original dataset) were excluded to simplify pre-processing.
Finally, in order to transform the dataset from a regression problem into a classification one,
the prices were binned into one of three price bins (low, average, or high) as shown in `Table 2`.
The cutoffs for each bin were chosen so that the resulting dataset was fairly balanced.

| Label | Bin (Home Price)     | Bin # | Counts | %     |
| ----- | -------------------- | ----- | ------ | ----- |
| Low   | $50000 - $725000     | 0     | 2205   | 35.6% |
| Avg   | $725000 - $1150000   | 1     | 1916   | 30.9% |
| High  | $1150000 - $10000000 | 2     | 2075   | 33.5% |

Table: Housing Dataset Labels

The second dataset chosen was related to the red variants of the Portuguese "Vinho Verde" wine
(hereafter referred to as *Wine*) and generated by UC Irvine (UCI).
*Quality* was selected as the label, while the other 11 columns were used as features.
Unlike the *Housing* dataset, this dataset necessitated very little pre-processing.
All features were numerical, so no encoding needed to be applied, and it was a complete dataset, with no null values.
However, with that said, was transformed into a binary classification problem for simplicity.
As shown in `Table 3`, wine quality was categorized as either *Bad* (0) or *Good* (1), with the cutoff at 5.5 and the
resulting dataset being fairly balanced.

| Label | Bin (Wine Quality) | Bin # | Counts | %     |
| ----- | ------------------ | ----- | ------ | ----- |
| Bad   | 1.0 - 5.5          | 0     | 744    | 46.5% |
| Good  | 5.5 - 10.0         | 1     | 855    | 53.5% |

Table: Wine Dataset Labels

While the datasets are certainly interesting in their own right, they are much more interesting
when compared and contrasted to each other.
One dataset (*Housing*) is fairly large (>10000 rows, 20 features) and needed a lot more cleaning during pre-processing,
while the other dataset (*Wine*) was pretty small (~1500 rows, 11 features), already cleaned, and likely
very well suited for machine learning as it was generated by UCI's Machine Learning group.

## Methodology

Both datasets were split using 75-25 splits, where 75% was used for training data and 25% for testing data.
Although both datasets did appear to be fairly balanced, a stratified shuffle split was performed to preserve
the percentage of samples for each class.
Both training data and testing data were standardized (to equalize the range and data variability)
and normalized (to bring all variables into the same range) since certain learners can be particularly
sensitive to data that isn't scaled or normalized, e.g. SVMs.

After pre-processing, the datasets were ready for ingestion by each learner.
An important note first though is that the test set was never touched during the model selection process
and was only used for testing the model.
For each learning algorithm, an "initial" run was first conducted using all of the default hyperparameters set by
*scikit-learn* for that particular model.
Then, came the tuning loop where each hyperparameter was isolated and iterated on, one at a time.
A coarse grid search was performed at the start to get a rough range for parameter values, followed by
repeated updates to the parameter range, where the model complexity curve and learning curve aided each update
on the quest to maximize the accuracy and cross validation score, while minimizing bias and variance.

## Analysis

### Decision Trees

<!---
Housing Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.5\textwidth]{figures/housing_DTLearner_learning_curve_initial.png}\hfill
    \includegraphics[width=.5\textwidth]{figures/housing_DTLearner_learning_curve_final.png}
    \caption{Housing Learning Curves}
\end{figure*}

<!---
Housing Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/housing_DTLearner_validation_curve_class_weight.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_DTLearner_validation_curve_max_depth.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_DTLearner_validation_curve_max_leaf_nodes.png}
    \caption{Housing Validation Curves}
\end{figure*}

<!---
Wine Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.5\textwidth]{figures/wine_DTLearner_learning_curve_initial.png}\hfill
    \includegraphics[width=.5\textwidth]{figures/wine_DTLearner_learning_curve_final.png}
    \caption{Wine Learning Curves}
\end{figure*}

<!---
Wine Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/wine_DTLearner_validation_curve_class_weight.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_DTLearner_validation_curve_max_depth.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_DTLearner_validation_curve_max_leaf_nodes.png}
    \caption{Wine Validation Curves}
\end{figure*}

| Dataset | class_weight | max_depth | max_leaf_nodes |
| ------- | ------------ | --------- | -------------- |
| Housing | "balanced"   | 9         | 91             |
| Wine | None            | 14        | 102            |

Table: Hyperparameters

| Dataset | Initial Accuracy | Initial Bias | Initial Variance | Final Accuracy | Final Bias | Final Variance |
| ------- | ---------------- | ------------ | ---------------- | -------------- | ---------- | -------------- |
| Housing | 0.726            | 0.162        | 0.178            | 0.753          | 0.180      | 0.137          |
| Wine    | 0.718            | 0.159        | 0.163            | 0.715          | 0.160      | 0.157          |

Table: Overall Metrics

\newpage

### Neural Networks

<!---
Initial Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_learning_curve_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_scalability_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_learning_curve_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_scalability_initial.png}
    \caption{Initial Learning Curves}
\end{figure*}

<!---
Final Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_learning_curve_final.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_scalability_final.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_learning_curve_final.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_scalability_final.png}
    \caption{Final Learning Curves}
\end{figure*}

<!---
Housing Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_validation_curve_alpha.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_validation_curve_batch_size.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_validation_curve_hidden_layer_sizes.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_NNLearner_validation_curve_max_iter.png}
    \caption{Housing Validation Curves}
\end{figure*}

<!---
Wine Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_validation_curve_alpha.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_validation_curve_batch_size.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_validation_curve_hidden_layer_sizes.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_NNLearner_validation_curve_max_iter.png}
    \caption{Wine Validation Curves}
\end{figure*}

| Dataset | alpha   | batch_size | hidden_layer_sizes | learning_rate | max_iter |
| ------- | ------- | ---------- | ------------------ | ------------- | -------- |
| Housing | 1.0     | 200        | ((30,), (30,))     | constant      | 200      |
| Wine    | 0.00001 | 200        | ((25,), (25,))     | constant      | 200      |

Table: Hyperparameters

| Dataset | Initial Accuracy | Initial Bias | Initial Variance | Final Accuracy | Final Bias | Final Variance |
| ------- | ---------------- | ------------ | ---------------- | -------------- | ---------- | -------------- |
| Housing | 0.762            | 0.197        | 0.066            | 0.775          | 0.195      | 0.051          |
| Wine    | 0.748            | 0.208        | 0.044            | 0.760          | 0.195      | 0.060          |

Table: Overall Metrics

\newpage

```


```

\newpage

### Boosting

<!---
Initial Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.5\textwidth]{figures/housing_BoostingLearner_learning_curve_initial.png}\hfill
    \includegraphics[width=.5\textwidth]{figures/wine_BoostingLearner_learning_curve_initial.png}
    \caption{Initial Learning Curves}
\end{figure*}

<!---
Final Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.5\textwidth]{figures/housing_BoostingLearner_learning_curve_final.png}\hfill
    \includegraphics[width=.5\textwidth]{figures/wine_BoostingLearner_learning_curve_final.png}
    \caption{Final Learning Curves}
\end{figure*}

<!---
Housing Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/housing_BoostingLearner_validation_curve_base_estimator.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_BoostingLearner_validation_curve_learning_rate.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_BoostingLearner_validation_curve_n_estimators.png}
    \caption{Housing Validation Curves}
\end{figure*}

<!---
Wine Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/wine_BoostingLearner_validation_curve_base_estimator.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_BoostingLearner_validation_curve_learning_rate.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_BoostingLearner_validation_curve_n_estimators.png}
    \caption{Wine Validation Curves}
\end{figure*}

| Dataset | learning_rate | base_estimator (max_depth) | n_estimators |
| ------- | ------------- | -------------------------- | ------------ |
| Housing | 0.7           | 2                          | 125          |
| Wine    | 1.0           | 1                          | 60           |

Table: Hyperparameters

| Dataset | Initial Accuracy | Initial Bias | Initial Variance | Final Accuracy | Final Bias | Final Variance |
| ------- | ---------------- | ------------ | ---------------- | -------------- | ---------- | -------------- |
| Housing | 0.731            | 0.225        | 0.075            | 0.769          | 0.181      | 0.086          |
| Wine    | 0.740            | 0.199        | 0.097            | 0.75           | 0.196      | 0.097          |

Table: Overall Metrics

\newpage

### Support Vector Machines

<!---
Learning Curves (rbf)
-->
\begin{figure*}[ht!]
    \includegraphics[width=.25\textwidth]{figures/housing_SVMLearner_learning_curve_rbf_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_SVMLearner_learning_curve_rbf_final.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_SVMLearner_learning_curve_rbf_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_SVMLearner_learning_curve_rbf_final.png}
    \caption{Learning Curves (rbf)}
\end{figure*}

<!---
Learning Curves (poly)
-->
\begin{figure*}[ht!]
    \includegraphics[width=.25\textwidth]{figures/housing_SVMLearner_learning_curve_poly_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/housing_SVMLearner_learning_curve_poly_final.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_SVMLearner_learning_curve_poly_initial.png}\hfill
    \includegraphics[width=.25\textwidth]{figures/wine_SVMLearner_learning_curve_poly_final.png}
    \caption{Learning Curves (poly)}
\end{figure*}

<!---
Housing Validation Curves (rbf)
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/housing_SVMLearner_validation_curve_C_rbf.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_SVMLearner_validation_curve_tol_rbf.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_SVMLearner_validation_curve_gamma_rbf.png}
    \caption{Housing Validation Curves (rbf)}
\end{figure*}

<!---
Housing Validation Curves (poly)
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/housing_SVMLearner_validation_curve_C_poly.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_SVMLearner_validation_curve_tol_poly.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_SVMLearner_validation_curve_degree_poly.png}
    \caption{Housing Validation Curves (poly)}
\end{figure*}

<!---
Wine Validation Curves (rbf)
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/wine_SVMLearner_validation_curve_C_rbf.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_SVMLearner_validation_curve_tol_rbf.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_SVMLearner_validation_curve_gamma_rbf.png}
    \caption{Wine Validation Curves (rbf)}
\end{figure*}

<!---
Wine Validation Curves (poly)
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/wine_SVMLearner_validation_curve_C_poly.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_SVMLearner_validation_curve_tol_poly.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_SVMLearner_validation_curve_degree_poly.png}
    \caption{Wine Validation Curves (poly)}
\end{figure*}

| Dataset | kernel | C    | tol  | gamma | degree |
| ------- | ------ | ---- | ---- | ----- | ------ |
| Housing | rbf    | 2.0  | 1e-3 | scale | N/A    |
| Housing | poly   | 14.0 | 1e-3 | scale | 3      |
| Wine    | rbf    | 8    | 1e-3 | scale | N/A    |
| Wine    | poly   | 38   | 1e-3 | scale | 1      |

Table: Hyperparameters

| Dataset | Kernel | Initial Accuracy | Initial Bias | Initial Variance | Final Accuracy | Final Bias | Final Variance |
| ------- | ------ | ---------------- | ------------ | ---------------- | -------------- | ---------- | -------------- |
| Housing | rbf    | 0.742            | 0.236        | 0.057            | 0.756          | 0.221      | 0.061          |
| Housing | poly   | 0.682            | 0.313        | 0.070            | 0.733          | 0.235      | 0.082          |
| Wine    | rbf    | 0.703            | 0.246        | 0.045            | 0.775          | 0.194      | 0.054          |
| Wine    | poly   | 0.630            | 0.324        | 0.038            | 0.752          | 0.205      | 0.244          |

Table: Overall Metrics

\newpage

### k-Nearest Neighbors

<!---
Initial Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.5\textwidth]{figures/housing_KNNLearner_learning_curve_initial.png}\hfill
    \includegraphics[width=.5\textwidth]{figures/wine_KNNLearner_learning_curve_initial.png}
    \caption{Initial Learning Curves}
\end{figure*}

<!---
Final Learning Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.5\textwidth]{figures/housing_KNNLearner_learning_curve_final.png}\hfill
    \includegraphics[width=.5\textwidth]{figures/wine_KNNLearner_learning_curve_final.png}
    \caption{Final Learning Curves}
\end{figure*}

<!---
Housing Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/housing_KNNLearner_validation_curve_metric.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_KNNLearner_validation_curve_n_neighbors.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/housing_KNNLearner_validation_curve_weights.png}
    \caption{Housing Validation Curves}
\end{figure*}

<!---
Wine Validation Curves
-->
\begin{figure*}[ht!]
    \includegraphics[width=.33\textwidth]{figures/wine_KNNLearner_validation_curve_metric.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_KNNLearner_validation_curve_n_neighbors.png}\hfill
    \includegraphics[width=.33\textwidth]{figures/wine_KNNLearner_validation_curve_weights.png}
    \caption{Wine Validation Curves}
\end{figure*}

| Dataset | metric    | n_estimators | weights |
| ------- | --------- | ------------ | ------- |
| Housing | manhattan | 16           | uniform |
| Wine    | minkowski | 5            | uniform |

Table: Hyperparameters

| Dataset | Initial Accuracy | Initial Bias | Initial Variance | Final Accuracy | Final Bias | Final Variance |
| ------- | ---------------- | ------------ | ---------------- | -------------- | ---------- | -------------- |
| Housing | 0.683            | 0.270        | 0.154            | 0.712          | 0.251      | 0.104          |
| Wine    | 0.680            | 0.215        | 0.118            | 0.680          | 0.215      | 0.118          |

Table: Overall Metrics

\newpage

## Conclusion

| Dataset | Metric | Initial/Final | Decision Tree | Neural Network | Boosting | SVM | KNN |
| ------- | ------ | ------------- | ------------- | -------------- | -------- | --- | --- |
| Wine | Accuracy | Initial | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Accuracy | Final | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Bias | Initial | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Bias | Final | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Variance | Initial | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Variance | Final | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Fit Time [sec] | N/A | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Wine | Predict Time [sec] | N/A | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Accuracy | Initial | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Accuracy | Final | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Bias | Initial | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Bias | Final | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Variance | Initial | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Variance | Final | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Fit Time [sec] | N/A | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |
| Housing | Predict Time [sec] | N/A | 1.23 | 1.23 | 1.23 | 1.23 | 1.23 |

Table: Learner Performances

## References

* Slack
* Piazza
* Modules/Lectures
* Decision Tree
    * Ref 1
    * Ref 2
